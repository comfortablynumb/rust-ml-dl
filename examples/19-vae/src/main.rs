//! # VAE: Variational Autoencoder
//!
//! This example explains Variational Autoencoders (VAE), a probabilistic generative
//! model that combines deep learning with variational inference to learn latent
//! representations and generate new data.
//!
//! ## Problem: Generating New Data
//!
//! **Goal:** Learn to generate realistic new samples
//!
//! ```
//! Training data: Images of handwritten digits
//! Goal: Generate NEW digit images that look real
//!
//! Challenge:
//! â€¢ Can't just memorize training data
//! â€¢ Need to learn the "essence" of digits
//! â€¢ Must be able to sample from learned distribution
//! ```
//!
//! ## Autoencoder Limitations
//!
//! **Standard Autoencoder:**
//! ```
//! Encoder: x â†’ z (latent code)
//! Decoder: z â†’ xÌ‚ (reconstruction)
//!
//! Training: Minimize ||x - xÌ‚||Â²
//!
//! Problem for generation:
//! â€¢ Latent space has "holes"
//! â€¢ Only trained points work well
//! â€¢ Random sampling â†’ garbage
//!
//! Example:
//! Training encodes "5" â†’ z=[2.1, 3.4]
//! Random z=[2.0, 3.0] â†’ Decoder output: nonsense âŒ
//! ```
//!
//! ## VAE: The Probabilistic Solution
//!
//! **Key Innovation:** Treat latent variables as probability distributions
//!
//! ```
//! Instead of: x â†’ z (point)
//! VAE learns: x â†’ p(z|x) (distribution)
//!
//! Specifically: p(z|x) = N(Î¼(x), ÏƒÂ²(x))
//! Where:
//! â€¢ Î¼(x): Mean vector (encoder output 1)
//! â€¢ ÏƒÂ²(x): Variance vector (encoder output 2)
//! â€¢ N(...): Normal/Gaussian distribution
//! ```
//!
//! ## VAE Architecture
//!
//! ```
//!              Input x (e.g., 28Ã—28 image)
//!                      â†“
//!            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//!            â”‚     Encoder     â”‚
//!            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//!                   â†“   â†“
//!                   Î¼   Ïƒ  â† TWO outputs
//!                   â†“   â†“
//!              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//!              â”‚ Reparameterize â”‚
//!              â”‚ z = Î¼ + ÏƒâŠ™Îµ  â”‚  Îµ ~ N(0,1)
//!              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//!                      â†“
//!                      z (latent code)
//!                      â†“
//!            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//!            â”‚     Decoder     â”‚
//!            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//!                      â†“
//!              Reconstruction xÌ‚
//! ```
//!
//! ### Encoder Network
//! ```
//! Input: x (e.g., 784-dim flattened image)
//! Hidden: Dense(512, ReLU) â†’ Dense(256, ReLU)
//! Outputs:
//!   Î¼ = Dense(latent_dim)  â† Mean
//!   log_ÏƒÂ² = Dense(latent_dim)  â† Log variance (for numerical stability)
//!
//! Why log variance?
//! â€¢ Ïƒ must be positive
//! â€¢ log(ÏƒÂ²) can be any real number
//! â€¢ More stable training
//! ```
//!
//! ### Reparameterization Trick
//! ```
//! Problem: Can't backpropagate through sampling!
//!
//! Naive: z ~ N(Î¼, ÏƒÂ²)
//! âŒ Sampling is not differentiable!
//!
//! Reparameterization trick:
//! Îµ ~ N(0, 1)  â† Sample from standard normal
//! z = Î¼ + Ïƒ âŠ™ Îµ  â† Deterministic transformation
//! âœ… Backprop works! Gradients flow through Î¼ and Ïƒ
//!
//! In code:
//! epsilon = random_normal(0, 1)
//! z = mu + sigma * epsilon
//! ```
//!
//! ### Decoder Network
//! ```
//! Input: z (latent_dim)
//! Hidden: Dense(256, ReLU) â†’ Dense(512, ReLU)
//! Output: Dense(784, Sigmoid)  â† Reconstruction
//!
//! Output range: [0, 1] (for images)
//! ```
//!
//! ## The VAE Loss Function
//!
//! **Two components:**
//!
//! ```
//! Total Loss = Reconstruction Loss + KL Divergence
//!
//! L(x) = L_recon + Î² Ã— KL
//! ```
//!
//! ### 1. Reconstruction Loss
//! ```
//! How well does xÌ‚ match x?
//!
//! For binary images (MNIST):
//! L_recon = -Î£ [x_i log(xÌ‚_i) + (1-x_i) log(1-xÌ‚_i)]
//!           â†‘
//!    Binary cross-entropy per pixel
//!
//! For continuous images:
//! L_recon = ||x - xÌ‚||Â²  (MSE)
//! ```
//!
//! ### 2. KL Divergence
//! ```
//! Kullback-Leibler Divergence:
//! Measures difference between two distributions
//!
//! KL[q(z|x) || p(z)]
//! Where:
//! â€¢ q(z|x) = N(Î¼, ÏƒÂ²): Encoder's distribution
//! â€¢ p(z) = N(0, I): Standard normal prior
//!
//! Intuition: Pull encoded distributions toward standard normal
//!
//! For Gaussian case (closed form):
//! KL = 0.5 Ã— Î£ [Î¼Â² + ÏƒÂ² - log(ÏƒÂ²) - 1]
//!
//! Why?
//! â€¢ Regularization: Prevent overfitting
//! â€¢ Continuity: Make latent space smooth
//! â€¢ Sampling: Can sample z ~ N(0,1) at test time
//! ```
//!
//! ### Why KL Divergence?
//!
//! ```
//! Without KL (just reconstruction):
//! â€¢ Encoder learns arbitrary Î¼, Ïƒ
//! â€¢ Latent space has "holes"
//! â€¢ Random z â†’ bad reconstructions
//!
//! With KL divergence:
//! â€¢ Forces Î¼ close to 0, Ïƒ close to 1
//! â€¢ Creates smooth, continuous latent space
//! â€¢ Any z ~ N(0,1) decodes to reasonable output
//!
//! Example:
//! Train on digits 0-9
//! Latent space organized:
//!
//!     0   1   2   3   4   5   6   7   8   9
//!     â†“   â†“   â†“   â†“   â†“   â†“   â†“   â†“   â†“   â†“
//!   [â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€]
//!              Smooth latent space
//!
//! Sample z in between â†’ Interpolated digits!
//! ```
//!
//! ## The Î²-VAE Variant
//!
//! ```
//! L = L_recon + Î² Ã— KL
//!
//! Î²=1: Standard VAE
//! Î²>1: Î²-VAE (emphasize disentanglement)
//! Î²<1: Emphasize reconstruction
//!
//! Î²=2-4: Often gives more disentangled features
//! Example: Separate latent dims for "rotation", "thickness", "digit type"
//! ```
//!
//! ## Training VAE
//!
//! ### Training Loop
//! ```
//! for batch in dataset:
//!     # Forward pass
//!     Î¼, log_ÏƒÂ² = encoder(x)
//!     Ïƒ = exp(0.5 Ã— log_ÏƒÂ²)
//!     Îµ = random_normal(0, 1)
//!     z = Î¼ + Ïƒ âŠ™ Îµ
//!     xÌ‚ = decoder(z)
//!
//!     # Compute losses
//!     L_recon = binary_crossentropy(x, xÌ‚)
//!     KL = 0.5 Ã— sum(Î¼Â² + ÏƒÂ² - log_ÏƒÂ² - 1)
//!     loss = L_recon + KL
//!
//!     # Backpropagation
//!     loss.backward()
//!     optimizer.step()
//! ```
//!
//! ### Hyperparameters
//! ```
//! Latent dimension: 2-512
//! â€¢ 2: Visualizable, limited capacity
//! â€¢ 10-20: Good for MNIST
//! â€¢ 128-512: Complex images (faces, etc.)
//!
//! Learning rate: 0.001 (Adam)
//! Batch size: 32-128
//! Epochs: 50-200
//! Î²: 1.0 (standard), 2-4 (disentangling)
//! ```
//!
//! ## Generation: Creating New Samples
//!
//! ### Random Generation
//! ```
//! # Sample from standard normal
//! z = random_normal(0, 1, size=latent_dim)
//!
//! # Decode to image
//! x_new = decoder(z)
//!
//! Result: Random but realistic sample!
//! ```
//!
//! ### Latent Space Interpolation
//! ```
//! # Encode two images
//! z1 = encoder(image1).Î¼  # "3"
//! z2 = encoder(image2).Î¼  # "8"
//!
//! # Interpolate in latent space
//! for Î± in [0, 0.2, 0.4, 0.6, 0.8, 1.0]:
//!     z = Î±Ã—z1 + (1-Î±)Ã—z2
//!     image = decoder(z)
//!     display(image)
//!
//! Result: Smooth morphing from 3 to 8!
//! ```
//!
//! ### Latent Space Arithmetic
//! ```
//! Given trained on faces:
//!
//! z_smiling = encoder(smiling_face)
//! z_neutral = encoder(neutral_face)
//! z_man = encoder(man_face)
//!
//! # "smile vector"
//! smile_vec = z_smiling - z_neutral
//!
//! # Add smile to man
//! z_smiling_man = z_man + smile_vec
//! smiling_man = decoder(z_smiling_man)
//!
//! Similar to Word2Vec: king - man + woman = queen
//! ```
//!
//! ## Conditional VAE (CVAE)
//!
//! **Add label information:**
//!
//! ```
//! Standard VAE:
//! Encoder: x â†’ z
//! Decoder: z â†’ xÌ‚
//!
//! Conditional VAE:
//! Encoder: [x, y] â†’ z  â† Concatenate input and label
//! Decoder: [z, y] â†’ xÌ‚  â† Concatenate latent and label
//!
//! Generation with CVAE:
//! z = random_normal(0, 1)
//! y = 5  â† Choose digit label
//! x = decoder([z, y])  â† Generate a "5"
//!
//! Control what you generate!
//! ```
//!
//! ## Applications
//!
//! ### Image Generation
//! ```
//! MNIST (digits):
//! â€¢ Latent dim: 10-20
//! â€¢ Generates realistic digits
//! â€¢ Interpolation between digits
//!
//! CelebA (faces):
//! â€¢ Latent dim: 128-256
//! â€¢ Generate new faces
//! â€¢ Control attributes (smile, glasses, age)
//! ```
//!
//! ### Anomaly Detection
//! ```
//! Train VAE on normal data
//!
//! At test time:
//! reconstruction_error = ||x - xÌ‚||Â²
//!
//! If reconstruction_error > threshold:
//!     â†’ Anomaly! (VAE can't reconstruct well)
//!
//! Use cases:
//! â€¢ Manufacturing defect detection
//! â€¢ Network intrusion detection
//! â€¢ Medical imaging abnormalities
//! ```
//!
//! ### Data Compression
//! ```
//! Encoder compresses: 784 dims â†’ 10 dims
//! Decoder decompresses: 10 dims â†’ 784 dims
//!
//! Similar to JPEG but learned end-to-end
//! Better for domain-specific data
//! ```
//!
//! ### Representation Learning
//! ```
//! Use Î¼ (latent mean) as features:
//!
//! 1. Train VAE on images (unsupervised)
//! 2. Extract z = encoder(x).Î¼
//! 3. Train classifier on z
//!
//! Benefits:
//! â€¢ Low-dimensional features
//! â€¢ Captures data structure
//! â€¢ Works with unlabeled data
//! ```
//!
//! ### Drug Discovery
//! ```
//! Molecular VAE:
//! â€¢ Encode molecules as SMILES strings
//! â€¢ Learn latent representation
//! â€¢ Generate new molecules
//! â€¢ Interpolate between known drugs
//!
//! Result: Discover novel drug candidates
//! ```
//!
//! ## VAE Variants & Extensions
//!
//! ### Î²-VAE
//! ```
//! L = L_recon + Î² Ã— KL  (Î² > 1)
//!
//! Benefits:
//! â€¢ More disentangled latent factors
//! â€¢ Separate dims for different attributes
//! â€¢ Better interpretability
//!
//! Example: One dim for rotation, one for thickness
//! ```
//!
//! ### Hierarchical VAE
//! ```
//! Multiple latent variables at different scales:
//!
//! x â†’ z1 (low-level features)
//!   â†’ z2 (mid-level features)
//!   â†’ z3 (high-level features)
//!
//! Better for complex, multi-scale data
//! ```
//!
//! ### VQ-VAE (Vector Quantized)
//! ```
//! Discrete latent space (codebook):
//!
//! Instead of: z ~ continuous Gaussian
//! Use: z âˆˆ {e1, e2, ..., eK}  â† Discrete codes
//!
//! Benefits:
//! â€¢ Easier to model with autoregressive models
//! â€¢ Powers DALL-E
//! â€¢ Better for high-quality images
//! ```
//!
//! ### Importance Weighted VAE (IWAE)
//! ```
//! Use multiple samples to estimate loss:
//! â€¢ Tighter bound on log-likelihood
//! â€¢ Better performance
//! â€¢ More computation
//! ```
//!
//! ## VAE vs Other Generative Models
//!
//! ### VAE vs GAN
//! ```
//! VAE:
//! âœ… Stable training
//! âœ… Probabilistic framework
//! âœ… Meaningful latent space
//! âœ… Works with small data
//! âŒ Blurry outputs
//! âŒ Lower sample quality
//!
//! GAN:
//! âœ… Sharp, high-quality outputs
//! âœ… State-of-the-art images
//! âŒ Training instability
//! âŒ Mode collapse
//! âŒ Less meaningful latent space
//!
//! Use VAE when:
//! â€¢ Need stable training
//! â€¢ Want latent representation
//! â€¢ Need to encode/decode
//! â€¢ Anomaly detection
//!
//! Use GAN when:
//! â€¢ Need highest quality
//! â€¢ Only generation (no encoding)
//! â€¢ Have expertise to tune training
//! ```
//!
//! ### VAE vs Diffusion Models
//! ```
//! VAE:
//! âœ… Fast generation (one forward pass)
//! âœ… Explicit latent space
//! âœ… Can encode and decode
//! âŒ Blurry outputs
//!
//! Diffusion (Stable Diffusion, DALL-E):
//! âœ… State-of-the-art quality
//! âœ… Sharp, detailed images
//! âœ… Controllable generation
//! âŒ Slow (many steps)
//! âŒ Can't easily encode
//!
//! Hybrid: Stable Diffusion uses VAE!
//! â€¢ VAE compresses image to latent
//! â€¢ Diffusion works in latent space
//! â€¢ VAE decoder produces final image
//! ```
//!
//! ### VAE vs Standard Autoencoder
//! ```
//! Standard AE:
//! â€¢ Deterministic: x â†’ z â†’ xÌ‚
//! â€¢ Can't generate (holes in latent space)
//! â€¢ Better reconstruction
//! â€¢ Use for compression, denoising
//!
//! VAE:
//! â€¢ Probabilistic: x â†’ p(z|x) â†’ xÌ‚
//! â€¢ Can generate (smooth latent space)
//! â€¢ Slightly worse reconstruction
//! â€¢ Use for generation, anomaly detection
//! ```
//!
//! ## Mathematical Foundation
//!
//! ### Evidence Lower Bound (ELBO)
//! ```
//! VAE maximizes ELBO, a lower bound on log p(x):
//!
//! log p(x) â‰¥ ELBO = ð”¼_q[log p(x|z)] - KL[q(z|x) || p(z)]
//!                   â†‘                   â†‘
//!              Reconstruction      Regularization
//!
//! Where:
//! â€¢ p(x|z): Decoder (likelihood)
//! â€¢ q(z|x): Encoder (approximate posterior)
//! â€¢ p(z): Prior (standard normal)
//!
//! VAE training = maximize ELBO = minimize -ELBO
//! ```
//!
//! ### Why "Variational"?
//! ```
//! Variational inference: Approximating intractable posteriors
//!
//! True posterior: p(z|x) = p(x|z)p(z) / p(x)
//!                                       â†‘
//!                           Intractable! (requires integrating over all z)
//!
//! Solution: Learn approximate q(z|x) â‰ˆ p(z|x)
//! This is the encoder!
//!
//! "Variational" = Using variational inference
//! ```
//!
//! ## Training Tips
//!
//! ### KL Annealing
//! ```
//! Problem: KL term can dominate early, preventing learning
//!
//! Solution: Gradually increase KL weight
//! L = L_recon + Î³(epoch) Ã— KL
//!
//! Î³(epoch):
//! Epochs 0-10: 0 â†’ 0.1
//! Epochs 10-50: 0.1 â†’ 1.0
//! Epochs 50+: 1.0
//!
//! Allows reconstruction to improve first
//! ```
//!
//! ### Free Bits
//! ```
//! Problem: Some latent dimensions collapse (not used)
//!
//! Solution: Ensure minimum KL per dimension
//! KL_free_bits = max(KL_dim, Î»)
//!
//! Î» = 0.5 (typical)
//! Forces each dimension to encode at least Î» bits
//! ```
//!
//! ### Batch Normalization
//! ```
//! Add to encoder/decoder:
//! Dense â†’ BatchNorm â†’ ReLU
//!
//! Benefits:
//! â€¢ Faster training
//! â€¢ Higher learning rates
//! â€¢ Better convergence
//! ```
//!
//! ## Debugging VAE Training
//!
//! ### Problem: Blurry Reconstructions
//! ```
//! Solutions:
//! â€¢ Increase latent dimension
//! â€¢ Reduce Î² (less KL weight)
//! â€¢ More encoder/decoder capacity
//! â€¢ Try different loss (perceptual loss)
//! ```
//!
//! ### Problem: Posterior Collapse
//! ```
//! Symptom: KL â†’ 0, latent not used
//!
//! Solutions:
//! â€¢ KL annealing
//! â€¢ Free bits
//! â€¢ Reduce decoder capacity
//! â€¢ Increase Î² gradually
//! ```
//!
//! ### Problem: Poor Generation
//! ```
//! Solutions:
//! â€¢ Check KL divergence (should be > 0)
//! â€¢ Ensure latent space is continuous
//! â€¢ Train longer
//! â€¢ Use conditional VAE for more control
//! ```
//!
//! ## Modern Impact
//!
//! **2013:** VAE introduced (Kingma & Welling)
//! - Probabilistic framework for deep generative models
//! - Reparameterization trick enabling backprop
//!
//! **2015-2017:** Extensions
//! - Î²-VAE for disentanglement
//! - Conditional VAE
//! - Hierarchical VAE
//!
//! **2018-2019:** Applied to complex domains
//! - VQ-VAE for images
//! - MolecularVAE for drug discovery
//! - Text VAE for language
//!
//! **2020-2021:** Hybrid models
//! - DALL-E uses VQ-VAE
//! - Stable Diffusion uses VAE encoder/decoder
//! - VAE as preprocessing for other models
//!
//! **2022+:** Still relevant
//! - Component in modern systems
//! - Anomaly detection
//! - Representation learning
//! - Fast generation when speed matters
//!
//! **Legacy:**
//! - Showed deep learning + probabilistic modeling work well together
//! - Reparameterization trick widely used
//! - Foundation for modern generative AI

fn main() {
    println!("=== Variational Autoencoder (VAE) ===\n");

    println!("This example explains VAE, a probabilistic generative model that");
    println!("learns smooth latent representations for generation and anomaly detection.\n");

    println!("ðŸ“š Key Concepts Covered:");
    println!("  â€¢ Probabilistic encoder (Î¼, Ïƒ)");
    println!("  â€¢ Reparameterization trick");
    println!("  â€¢ ELBO loss (reconstruction + KL divergence)");
    println!("  â€¢ Latent space interpolation");
    println!("  â€¢ Generation vs standard autoencoders");
    println!("  â€¢ Î²-VAE for disentanglement\n");

    println!("ðŸŽ¯ Why This Matters:");
    println!("  â€¢ Foundation of probabilistic deep learning");
    println!("  â€¢ Powers modern systems (Stable Diffusion uses VAE)");
    println!("  â€¢ Enables controlled generation");
    println!("  â€¢ Critical for anomaly detection");
    println!("  â€¢ Smooth latent space for interpolation\n");

    println!("See the source code documentation for comprehensive explanations!");
}
